// lib/openai.ts
// Simple OpenAI Configuration - à¦à¦•à¦‡ API key à¦¦à¦¿à¦¯à¦¼à§‡ à¦…à¦¨à§‡à¦• models

import OpenAI from "openai";

// ============================================
// OpenAI Client (à¦à¦•à¦¬à¦¾à¦° initialize à¦•à¦°à§‹)
// ============================================

export const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY,
});

// ============================================
// TYPES
// ============================================

export interface AISuggestions {
  subtasks: string[];
  priority: "low" | "medium" | "high";
  timeEstimate: number;
  tips?: string[];
  aiModel?: string;
  success?: boolean;
  error?: string;
}

// ============================================
// Fallback Suggestions
// ============================================

export const FALLBACK_SUGGESTIONS: AISuggestions = {
  subtasks: [
    "Research and gather requirements",
    "Create a detailed action plan",
    "Break down into smaller milestones",
    "Execute step by step",
    "Review and optimize the results"
  ],
  priority: "medium",
  timeEstimate: 90,
  tips: [
    "Start with the most critical part first",
    "Set specific deadlines for each subtask",
    "Review progress regularly"
  ],
  aiModel: "fallback",
  success: false
};

// ============================================
// OpenAI Models List (same API key à¦¦à¦¿à¦¯à¦¼à§‡ à¦¸à¦¬ à¦•à¦¾à¦œ à¦•à¦°à¦¬à§‡)
// ============================================

const OPENAI_MODELS = [
  "gpt-4o",              // à¦¸à¦¬à¦šà§‡à¦¯à¦¼à§‡ powerful
  "gpt-4o-mini",         // fast à¦à¦¬à¦‚ à¦¸à¦¸à§à¦¤à¦¾ (Recommended!)
  "gpt-3.5-turbo",       // à¦¸à¦¬à¦šà§‡à¦¯à¦¼à§‡ à¦¸à¦¸à§à¦¤à¦¾ à¦à¦¬à¦‚ à¦¦à§à¦°à§à¦¤
  "gpt-4-turbo",         // à¦­à¦¾à¦²à§‹ quality
];

// ============================================
// System Prompt
// ============================================

const SYSTEM_PROMPT = `You are a smart task management assistant. 
When given a task, provide:
1. 3-5 specific, actionable subtasks
2. Priority (low/medium/high)
3. Time estimate in minutes
4. 2-3 helpful tips

IMPORTANT: Respond with ONLY valid JSON in this exact format:
{
  "subtasks": ["step 1", "step 2", "step 3"],
  "priority": "medium",
  "timeEstimate": 60,
  "tips": ["tip 1", "tip 2"]
}`;

// ============================================
// Response Parse à¦•à¦°à¦¾à¦° function
// ============================================

function parseResponse(text: string): any {
  let clean = text.trim();
  
  // Markdown remove à¦•à¦°à§‹
  if (clean.includes("```json")) {
    clean = clean.replace(/```json\n?/g, "").replace(/```\n?/g, "");
  } else if (clean.includes("```")) {
    clean = clean.replace(/```\n?/g, "");
  }
  
  // JSON à¦–à§à¦à¦œà§‡ à¦¬à§‡à¦° à¦•à¦°à§‹
  const jsonMatch = clean.match(/\{[\s\S]*\}/);
  if (jsonMatch) {
    clean = jsonMatch[0];
  }
  
  return JSON.parse(clean.trim());
}

// ============================================
// à¦à¦•à¦Ÿà¦¾ Model Try à¦•à¦°à§‹
// ============================================

async function tryModel(
  modelName: string, 
  title: string, 
  description: string
): Promise<AISuggestions> {
  
  console.log(`ğŸ¤– Trying: ${modelName}...`);
  
  const completion = await openai.chat.completions.create({
    model: modelName,
    messages: [
      { role: "system", content: SYSTEM_PROMPT },
      { 
        role: "user", 
        content: `Task: ${title}\nDescription: ${description || "None"}\n\nProvide JSON only.` 
      }
    ],
    temperature: 0.7,
    max_tokens: 600,
  });

  const responseText = completion.choices[0]?.message?.content?.trim();
  
  if (!responseText) {
    throw new Error("Empty response");
  }

  const data = parseResponse(responseText);

  // Check à¦•à¦°à§‹ response à¦ à¦¿à¦• à¦†à¦›à§‡ à¦•à¦¿à¦¨à¦¾
  if (!data.subtasks || !Array.isArray(data.subtasks) || data.subtasks.length === 0) {
    throw new Error("Invalid response");
  }

  console.log(`âœ… ${modelName} worked!`);

  return {
    subtasks: data.subtasks,
    priority: data.priority || "medium",
    timeEstimate: data.timeEstimate || 60,
    tips: data.tips || [],
    aiModel: modelName,
    success: true
  };
}

// ============================================
// MAIN FUNCTION - AI Suggestions à¦ªà¦¾à¦“
// ============================================

export async function getAISuggestions(
  title: string,
  description?: string
): Promise<AISuggestions> {
  
  console.log("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”");
  console.log("ğŸš€ Getting AI Suggestions...");
  console.log("Title:", title);
  console.log("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”");

  const desc = description || "";

  // à¦à¦•à¦Ÿà¦¾à¦° à¦ªà¦° à¦à¦•à¦Ÿà¦¾ model try à¦•à¦°à§‹
  for (const modelName of OPENAI_MODELS) {
    try {
      const result = await tryModel(modelName, title, desc);
      
      // Success! à¦¸à¦¾à¦¥à§‡ à¦¸à¦¾à¦¥à§‡ return à¦•à¦°à§‹
      console.log("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”");
      console.log("âœ… Success with:", modelName);
      console.log("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”");
      
      return result;
      
    } catch (error: any) {
      console.log(`âŒ ${modelName} failed:`, error.message);
      console.log(`âš ï¸ Trying next model...`);
      // à¦ªà¦°à§‡à¦° model try à¦•à¦°à§‹
      continue;
    }
  }

  // à¦¸à¦¬ models fail à¦•à¦°à¦²à§‡ fallback à¦¦à¦¾à¦“
  console.log("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”");
  console.log("âš ï¸ All models failed!");
  console.log("Using fallback suggestions");
  console.log("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”");
  
  return {
    ...FALLBACK_SUGGESTIONS,
    error: "All OpenAI models failed"
  };
}